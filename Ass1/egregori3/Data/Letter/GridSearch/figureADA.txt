Loading LETTER dataset
Integer Encoding dataset
[[ 2  8  3 ...,  8  0  8]
 [ 5 12  3 ...,  8  4 10]
 [ 4 11  6 ...,  7  3  9]
 ..., 
 [ 6  9  6 ..., 12  2  4]
 [ 2  3  4 ...,  9  5  8]
 [ 4  9  6 ...,  7  2  8]]
[19  8  3 ..., 19 18  0]
Tuning hyper-parameters for accuracy


20, 0.307, 0.317, 0.148, 0.045, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 10}
15, 0.387, 0.396, 0.293, 0.085, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 20}
9, 0.441, 0.452, 0.429, 0.147, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 30}
6, 0.573, 0.604, 1.488, 0.477, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 100}
1, 0.631, 0.678, 2.970, 0.805, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 200}
19, 0.330, 0.340, 0.156, 0.041, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 10}
13, 0.403, 0.418, 0.293, 0.068, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 20}
10, 0.439, 0.458, 0.479, 0.119, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 30}
5, 0.573, 0.607, 1.532, 0.404, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 100}
4, 0.614, 0.649, 3.005, 0.788, {'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 200}
17, 0.346, 0.356, 0.167, 0.039, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 10}
16, 0.360, 0.376, 0.288, 0.079, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 20}
11, 0.434, 0.440, 0.472, 0.118, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 30}
8, 0.572, 0.605, 1.457, 0.340, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 100}
2, 0.628, 0.668, 2.816, 0.654, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 200}
18, 0.335, 0.340, 0.130, 0.036, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 10}
14, 0.394, 0.406, 0.253, 0.065, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 20}
12, 0.418, 0.431, 0.431, 0.102, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 30}
7, 0.573, 0.608, 1.364, 0.334, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 100}
3, 0.619, 0.654, 2.728, 0.646, {'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'log2', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 200}

Best parameters set found on development set LETTER
{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 200}

Best parameters classification report LETTER

             precision    recall  f1-score   support

          0       0.94      0.76      0.84       216
          1       0.68      0.72      0.70       239
          2       0.66      0.76      0.71       229
          3       0.58      0.75      0.65       248
          4       0.62      0.61      0.62       221
          5       0.73      0.77      0.75       246
          6       0.51      0.51      0.51       256
          7       0.40      0.60      0.48       202
          8       0.65      0.56      0.60       218
          9       0.76      0.72      0.74       233
         10       0.68      0.59      0.63       207
         11       0.75      0.55      0.63       231
         12       0.92      0.34      0.50       251
         13       0.65      0.80      0.72       223
         14       0.66      0.81      0.72       226
         15       0.95      0.71      0.81       249
         16       0.66      0.76      0.71       215
         17       0.69      0.67      0.68       234
         18       0.48      0.62      0.54       222
         19       0.58      0.62      0.60       237
         20       0.72      0.83      0.77       241
         21       0.55      0.85      0.67       247
         22       0.87      0.40      0.55       215
         23       0.61      0.77      0.68       245
         24       0.51      0.40      0.45       238
         25       0.59      0.24      0.34       211

avg / total       0.67      0.65      0.64      6000


Classification report
Parameters:
{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__splitter': 'best', 'n_estimators': 200}
             precision    recall  f1-score   support

          0       0.93      0.66      0.77       216
          1       0.70      0.70      0.70       239
          2       0.72      0.72      0.72       229
          3       0.64      0.77      0.70       248
          4       0.55      0.69      0.61       221
          5       0.57      0.78      0.66       246
          6       0.48      0.51      0.49       256
          7       0.27      0.66      0.38       202
          8       0.60      0.71      0.65       218
          9       0.85      0.64      0.73       233
         10       0.47      0.36      0.40       207
         11       0.74      0.49      0.59       231
         12       0.91      0.27      0.41       251
         13       0.56      0.51      0.53       223
         14       0.62      0.79      0.69       226
         15       0.94      0.68      0.79       249
         16       0.70      0.77      0.73       215
         17       0.69      0.56      0.62       234
         18       0.41      0.59      0.48       222
         19       0.59      0.59      0.59       237
         20       0.74      0.82      0.78       241
         21       0.49      0.86      0.62       247
         22       0.83      0.11      0.20       215
         23       0.62      0.71      0.66       245
         24       0.70      0.41      0.52       238
         25       0.59      0.20      0.30       211

avg / total       0.65      0.60      0.59      6000


Confusion matrix, without normalization
[[159   0   0   0   0   0   9   6   5  14   0   0   0   0   0   0  12   3
    8   0   0   0   0   0   0   0]
 [  0 131   0   0   0   0   2   6  15   1   5   8   0   0   0   0   0  33
   26   0   0   9   0   1   2   0]
 [  0   0 147   0  16   0  36   1   0   0   1   6   0   0   1   0   2   0
    6  10   1   0   0   2   0   0]
 [  0   7   0 128   0   2   1  54   4   0   1   0   0   2  33   2   4   5
    1   1   3   0   0   0   0   0]
 [  0   0   3   0 138   0  14   2   0   0   6   9   0   0   0   0   2   0
   14  14   0   0   0  19   0   0]
 [  0   2   1   0   4 188   2   9   5   1   0   0   0   8   0   9   0   0
    3  10   0   1   0   0   3   0]
 [  0   1  35   2   4   0 135   4   0   0   5  13   0   0  14   0  21   3
    9   0   0   9   1   0   0   0]
 [  0   5   0   7   0   1   2 104   1   0   4   0   0   0  52   0   5   6
    1   2   7   2   0   1   1   1]
 [  0   1   0   0   1   3   1   0 139   5   0   0   0   0   0   0   0   1
   19   0   0   0   0  46   0   2]
 [  0   2   0   4   0   4   0   1  32 129   1   1   0   1  27   0  14   1
   13   0   1   0   0   0   0   2]
 [  0   1   4   1  13   1  31  28   0   0  92   1   0   0  10   0   0  10
    1   0   1   0   0  13   0   0]
 [  0   1   0  75   2   0   6   6  51   5   0  57   0   0   5   0   1   1
   18   3   0   0   0   0   0   0]
 [  7   3   0   0   0   0   2  23   0   0   0   0 102  24  18   1   2   0
    0   0  61   3   5   0   0   0]
 [  0   2   0   3   0   0   0  12   0   0   3   0   1 174  25   0   0   1
    0   0   0   2   0   0   0   0]
 [  0   1   3   2   0   0   0  17   0   1   0   0   0   0 179   1  11   1
    0   0   4   4   2   0   0   0]
 [  0   5   3   1   0  21   3  11   5   0   0   0   0   1  12 173   1   0
    2   0   0   1   0   0  10   0]
 [  0   1   0   0   2   0  11   0   0   0   0   0   1   0   8   0 162   0
   28   0   0   0   0   0   2   0]
 [  0   5   0   8   2   0  17  13   6   2   4   0   0   6  20   0   0 146
    1   0   0   0   0   4   0   0]
 [  0  12   0   0  17   1   2   2  12   1   0   0   0   0   3   0   2   0
  129  11   0   0   0   7   0  23]
 [  0   1   2   0   2  63   0   1   0   1   1   1   0   0   0   1   0   1
    6 139   0   0   0   7  11   0]
 [  0   0   4   1   0   0   0  12   0   0   1   0   1   0   1   0   1   0
    0  26 188   6   0   0   0   0]
 [  0   5   1   0   0   2   0   3   0   0   0   0   0   1   9   0   0   0
    0   1   1 190   0   0  34   0]
 [  0   1   0   0   0   0   0   1   0   0   0   0   4  57   3   1   0   0
    0   0   1  77  70   0   0   0]
 [  0   4   0   2   2   2   0  12  11   2  12  12   0   0   1   0   0   4
    3   9   0   0   0 169   0   0]
 [  0   0   0   0   0  23   0   3   0   0   0   0   0   1   0   1   2   0
    4  48   1  43   0   0 110   2]
 [  0   2   2   1  91   7   0   1  12   8   0   0   0   0   0   0   2   0
   26   6   0   0   0  16   0  37]]
