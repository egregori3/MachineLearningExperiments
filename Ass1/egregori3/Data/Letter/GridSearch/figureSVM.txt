Loading LETTER dataset
Integer Encoding dataset
[[ 2  8  3 ...,  8  0  8]
 [ 5 12  3 ...,  8  4 10]
 [ 4 11  6 ...,  7  3  9]
 ..., 
 [ 6  9  6 ..., 12  2  4]
 [ 2  3  4 ...,  9  5  8]
 [ 4  9  6 ...,  7  2  8]]
[19  8  3 ..., 19 18  0]
Tuning hyper-parameters for accuracy


37, 0.041, 0.041, 5.970, 2.424, {'C': 1, 'degree': 1, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 5.384, 2.388, {'C': 1, 'degree': 1, 'gamma': 0, 'kernel': 'poly'}
19, 0.938, 1.000, 9.343, 2.439, {'C': 1, 'degree': 1, 'gamma': 10, 'kernel': 'rbf'}
33, 0.841, 0.868, 1.568, 1.080, {'C': 1, 'degree': 1, 'gamma': 10, 'kernel': 'poly'}
34, 0.834, 1.000, 9.593, 2.716, {'C': 1, 'degree': 1, 'gamma': 20, 'kernel': 'rbf'}
24, 0.845, 0.874, 1.781, 1.036, {'C': 1, 'degree': 1, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 6.266, 2.542, {'C': 1, 'degree': 2, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 4.821, 2.198, {'C': 1, 'degree': 2, 'gamma': 0, 'kernel': 'poly'}
19, 0.938, 1.000, 7.543, 2.145, {'C': 1, 'degree': 2, 'gamma': 10, 'kernel': 'rbf'}
1, 0.942, 0.999, 1.239, 0.826, {'C': 1, 'degree': 2, 'gamma': 10, 'kernel': 'poly'}
34, 0.834, 1.000, 9.168, 2.909, {'C': 1, 'degree': 2, 'gamma': 20, 'kernel': 'rbf'}
16, 0.940, 1.000, 1.563, 0.904, {'C': 1, 'degree': 2, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 5.482, 2.668, {'C': 1, 'degree': 3, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 4.884, 2.537, {'C': 1, 'degree': 3, 'gamma': 0, 'kernel': 'poly'}
19, 0.938, 1.000, 8.618, 2.521, {'C': 1, 'degree': 3, 'gamma': 10, 'kernel': 'rbf'}
2, 0.942, 1.000, 1.106, 0.859, {'C': 1, 'degree': 3, 'gamma': 10, 'kernel': 'poly'}
34, 0.834, 1.000, 7.844, 2.413, {'C': 1, 'degree': 3, 'gamma': 20, 'kernel': 'rbf'}
2, 0.942, 1.000, 0.994, 0.795, {'C': 1, 'degree': 3, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 4.483, 2.053, {'C': 2, 'degree': 1, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 3.944, 2.096, {'C': 2, 'degree': 1, 'gamma': 0, 'kernel': 'poly'}
11, 0.940, 1.000, 7.272, 2.039, {'C': 2, 'degree': 1, 'gamma': 10, 'kernel': 'rbf'}
24, 0.845, 0.874, 1.249, 0.875, {'C': 2, 'degree': 1, 'gamma': 10, 'kernel': 'poly'}
27, 0.844, 1.000, 7.311, 2.272, {'C': 2, 'degree': 1, 'gamma': 20, 'kernel': 'rbf'}
23, 0.845, 0.879, 1.500, 0.851, {'C': 2, 'degree': 1, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 4.447, 2.040, {'C': 2, 'degree': 2, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 4.010, 2.007, {'C': 2, 'degree': 2, 'gamma': 0, 'kernel': 'poly'}
11, 0.940, 1.000, 7.042, 1.990, {'C': 2, 'degree': 2, 'gamma': 10, 'kernel': 'rbf'}
15, 0.940, 1.000, 1.141, 0.745, {'C': 2, 'degree': 2, 'gamma': 10, 'kernel': 'poly'}
27, 0.844, 1.000, 7.297, 2.254, {'C': 2, 'degree': 2, 'gamma': 20, 'kernel': 'rbf'}
17, 0.940, 1.000, 1.148, 0.741, {'C': 2, 'degree': 2, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 4.557, 2.094, {'C': 2, 'degree': 3, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 4.266, 2.119, {'C': 2, 'degree': 3, 'gamma': 0, 'kernel': 'poly'}
11, 0.940, 1.000, 7.222, 2.041, {'C': 2, 'degree': 3, 'gamma': 10, 'kernel': 'rbf'}
2, 0.942, 1.000, 0.964, 0.781, {'C': 2, 'degree': 3, 'gamma': 10, 'kernel': 'poly'}
27, 0.844, 1.000, 7.339, 2.275, {'C': 2, 'degree': 3, 'gamma': 20, 'kernel': 'rbf'}
2, 0.942, 1.000, 0.992, 0.820, {'C': 2, 'degree': 3, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 4.696, 2.140, {'C': 3, 'degree': 1, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 3.836, 2.006, {'C': 3, 'degree': 1, 'gamma': 0, 'kernel': 'poly'}
8, 0.940, 1.000, 7.255, 2.026, {'C': 3, 'degree': 1, 'gamma': 10, 'kernel': 'rbf'}
22, 0.846, 0.876, 1.388, 0.868, {'C': 3, 'degree': 1, 'gamma': 10, 'kernel': 'poly'}
27, 0.844, 1.000, 7.558, 2.314, {'C': 3, 'degree': 1, 'gamma': 20, 'kernel': 'rbf'}
26, 0.844, 0.880, 1.894, 0.878, {'C': 3, 'degree': 1, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 4.605, 2.124, {'C': 3, 'degree': 2, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 4.140, 2.095, {'C': 3, 'degree': 2, 'gamma': 0, 'kernel': 'poly'}
8, 0.940, 1.000, 7.405, 2.112, {'C': 3, 'degree': 2, 'gamma': 10, 'kernel': 'rbf'}
14, 0.940, 1.000, 1.232, 0.786, {'C': 3, 'degree': 2, 'gamma': 10, 'kernel': 'poly'}
27, 0.844, 1.000, 7.715, 2.420, {'C': 3, 'degree': 2, 'gamma': 20, 'kernel': 'rbf'}
18, 0.939, 1.000, 1.142, 0.742, {'C': 3, 'degree': 2, 'gamma': 20, 'kernel': 'poly'}
37, 0.041, 0.041, 4.470, 2.069, {'C': 3, 'degree': 3, 'gamma': 0, 'kernel': 'rbf'}
37, 0.041, 0.041, 4.105, 2.023, {'C': 3, 'degree': 3, 'gamma': 0, 'kernel': 'poly'}
8, 0.940, 1.000, 7.125, 2.067, {'C': 3, 'degree': 3, 'gamma': 10, 'kernel': 'rbf'}
2, 0.942, 1.000, 0.967, 0.781, {'C': 3, 'degree': 3, 'gamma': 10, 'kernel': 'poly'}
27, 0.844, 1.000, 7.696, 2.368, {'C': 3, 'degree': 3, 'gamma': 20, 'kernel': 'rbf'}
2, 0.942, 1.000, 1.030, 0.825, {'C': 3, 'degree': 3, 'gamma': 20, 'kernel': 'poly'}

Best parameters set found on development set LETTER
{'C': 1, 'degree': 2, 'gamma': 10, 'kernel': 'poly'}

Best parameters classification report LETTER

             precision    recall  f1-score   support

          0       0.99      0.98      0.99       216
          1       0.91      0.94      0.92       239
          2       0.94      0.97      0.95       229
          3       0.94      0.96      0.95       248
          4       0.92      0.96      0.94       221
          5       0.96      0.96      0.96       246
          6       0.93      0.90      0.92       256
          7       0.86      0.91      0.88       202
          8       0.98      0.94      0.96       218
          9       0.95      0.94      0.94       233
         10       0.92      0.92      0.92       207
         11       0.98      0.97      0.98       231
         12       0.98      0.99      0.99       251
         13       0.96      0.98      0.97       223
         14       0.96      0.94      0.95       226
         15       0.97      0.96      0.97       249
         16       0.98      0.96      0.97       215
         17       0.93      0.93      0.93       234
         18       0.97      0.99      0.98       222
         19       0.97      0.98      0.98       237
         20       0.98      0.97      0.97       241
         21       0.95      0.95      0.95       247
         22       0.98      0.98      0.98       215
         23       0.98      0.95      0.97       245
         24       0.97      0.97      0.97       238
         25       1.00      0.99      0.99       211

avg / total       0.96      0.96      0.96      6000


Classification report
Parameters:
{'C': 1, 'degree': 2, 'gamma': 10, 'kernel': 'poly'}
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       216
          1       0.91      0.94      0.92       239
          2       0.94      0.97      0.95       229
          3       0.94      0.96      0.95       248
          4       0.92      0.96      0.94       221
          5       0.96      0.96      0.96       246
          6       0.93      0.90      0.92       256
          7       0.86      0.91      0.88       202
          8       0.98      0.94      0.96       218
          9       0.95      0.94      0.94       233
         10       0.92      0.92      0.92       207
         11       0.98      0.97      0.98       231
         12       0.98      0.99      0.99       251
         13       0.96      0.98      0.97       223
         14       0.96      0.94      0.95       226
         15       0.97      0.96      0.97       249
         16       0.98      0.96      0.97       215
         17       0.93      0.93      0.93       234
         18       0.97      0.99      0.98       222
         19       0.97      0.98      0.98       237
         20       0.98      0.97      0.97       241
         21       0.95      0.95      0.95       247
         22       0.98      0.98      0.98       215
         23       0.98      0.95      0.97       245
         24       0.97      0.97      0.97       238
         25       1.00      0.99      0.99       211

avg / total       0.96      0.96      0.96      6000


Confusion matrix, without normalization
[[212   0   0   1   0   0   3   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0]
 [  0 224   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   4
    4   0   0   6   0   0   0   0]
 [  0   0 222   0   2   0   4   1   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0]
 [  0   2   0 237   0   0   2   2   0   0   0   0   0   0   1   1   0   1
    0   1   1   0   0   0   0   0]
 [  0   1   2   0 213   0   2   0   0   0   0   2   0   0   0   0   1   0
    0   0   0   0   0   0   0   0]
 [  0   1   0   2   1 236   0   0   0   0   0   0   0   0   0   3   0   0
    0   2   0   1   0   0   0   0]
 [  0   0   3   3   5   0 230   2   0   0   4   2   0   0   4   2   0   0
    0   0   0   1   0   0   0   0]
 [  0   4   3   2   0   0   0 183   0   2   4   0   0   1   0   1   0   1
    0   0   0   0   0   0   1   0]
 [  0   0   1   1   0   0   0   0 206  10   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0]
 [  1   2   0   0   0   3   0   1   4 219   0   0   0   0   1   0   0   0
    1   0   0   0   0   0   0   1]
 [  0   0   1   0   1   0   0   8   0   0 190   0   0   0   0   0   0   6
    0   0   0   0   0   1   0   0]
 [  0   0   0   1   0   0   0   3   0   0   1 225   0   0   0   0   0   1
    0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   1   0   0   0   0 248   0   0   0   0   0
    0   0   0   0   1   0   0   0]
 [  0   0   1   1   0   0   0   0   0   0   0   0   1 218   0   0   0   0
    0   0   1   0   1   0   0   0]
 [  0   0   3   1   0   0   1   1   0   0   0   0   0   2 212   1   2   1
    0   0   1   0   1   0   0   0]
 [  0   0   0   1   2   3   0   1   0   0   0   0   0   0   1 240   1   0
    0   0   0   0   0   0   0   0]
 [  0   0   0   0   3   1   3   0   0   0   0   0   0   0   2   0 206   0
    0   0   0   0   0   0   0   0]
 [  0   6   0   1   0   0   0   3   0   0   3   0   0   4   0   0   0 217
    0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0
  219   0   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0
    0 232   1   0   0   2   0   0]
 [  0   0   0   0   0   0   0   2   0   0   0   0   3   1   0   0   0   0
    0   0 233   1   1   0   0   0]
 [  0   5   0   0   0   1   0   2   0   0   0   0   0   0   0   0   0   0
    0   0   0 234   1   0   4   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0
    0   0   0   2 210   0   1   0]
 [  0   0   0   2   2   0   0   1   1   0   4   0   0   0   0   0   0   2
    0   0   0   0   0 233   0   0]
 [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0
    2   3   0   1   0   1 230   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0 209]]
